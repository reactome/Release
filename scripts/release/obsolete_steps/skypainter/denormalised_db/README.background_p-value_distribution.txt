BACKGROUND
Skypainter determines which events (reactions and/or pathways) are statistically overrepresented in a set of genes as specified by submitted list of identifiers. In other words, given a list of genes, Skypainter can identify common events for these genes.
Given a set of M genes which participate in an event, the total of X genes (for the given species) that Reactome is aware of, and given the submitted list of K genes of which N genes participate in the given event, skypainter calculates (by performing the one-tailed version of Fisher\'s exact test, http://en.wikipedia.org/wiki/Fisher%27s_exact_test) the probability of observing at least N genes from an event if the event is not overrepresented in the submitted list of genes. Hence the p-value smaller than or equal to the significance level suggests that the event is indeed overrepresented in the submitted list of genes.

PROBLEM
When multiple statistical tests are performed in a single study - as is the case in skypainter analysis where a given set is compared against - the probability of Type I error (false positives) increases and is no longer accurately reflected by unadjusted p-values (see e.g. http://en.wikipedia.org/wiki/Multiple_testing).

SOLUTION
There are various ways of correcting for multiple testing with the Bonferroni method being the simplest but arguably the most conservative, i.e. suggesting that an event is not overrepresented among the genes analysed whereas it actually is. One method for avoiding this kind of inflation of the rate of false negatives is empirical estimation of the frequency of false positives by performing repeated random resampling (a.k.a Monte Carlo simulation). I.e. given X genes in a given species in Reactome, select K genes at random, do one-tailed version of Fisher\'s exact test for each event in which any of the genes participate and record the the lowest p-value. Repeat the procedure for appropriate number of times (e.g. 1000). As result we get a list of p-values - background p-value distribution. The fraction of those which are equal to or lower than the p-value that we obtained by analysing the "real" gene set shows the expected proportion of false positives (False Discovery Rate - FDR).
IS THIS THE RIGHT APPROACH? Rather than recording the lowest p-value - which could come from any event - for a random sample perhaps we should record the p-value for each event? This would then show how often we should expect to see this particular event as a false positive. I think Guanming uses this approach. FDRs estimated this way would be lower than the ones obtained with the methodology above. I THINK THIS NEEDS TO BE CHECKED WITH A STATISTICIAN.

IMPLEMENTATION
Random resampling takes time - far too much for doing it on the fly. It would also be wasteful: as the resampling procedure above ignores the composition and only considers the size of the set being analysed, 2 genesets with same size (K) but different composition should have identical background p-value distributions. Hence we can compute these in advance and conveniently store them in the same db as instances of the BackgroundPvalueDistribution class.
As the background p-value distribution depends on the set size and as the p-value calculation also uses the number of genes in a given species in Reactome (X) we need to compute it for each set size in each species. Arguably, it may be possible to estimate the background p-value distribution for a set sizes according to its "neighbours", i.e. compute it for sets of 10 and 20 and estimate for sets of 11..19. I think Reimand & Vilo have tried that.

There are 3 scripts for calculating the background p-value distribution. compute_and_store_background_p_value_distribution.pl does it for a single species, compute_and_store_background_p_value_distribution_4_some_species.pl for some species (as specified in the script) and compute_and_store_background_p_value_distribution_4_all_species.pl for all species. All of the expect to get the range of set sizes for which background p-values are calculated. This should be specified with -start and -stop commandline parameters. By default all perform 1000 iterations but this can be changed with the -iter commandline parameter. The code doing the work is in the GKB::SkyPainter module.
As already mentioned, random resampling takes time. On the brie8 that we got in autumn 2008 (8x Intel Xeon X5460@3.16GHz) it takes ~1.5 hours to do 1000 iterations for human set sizes 2..100 (this is with release 26). I've also seen this taking much longer. As yet I don't know the explanation - it may have something to do with the other jobs on the server. Compute time increase with the set size - covering range 101..200 took about 14 hours if I remember correctly.
It should be possible to parallellise the compute moderately by e.g. running different species in parallel. I've tried this on waterlily (8x AMD Opteron 850) with 4 parallel processes agains the same db. 


